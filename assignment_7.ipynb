{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94165f3d",
   "metadata": {},
   "source": [
    "# Assignment 7\n",
    "### Do any five.\n",
    "### Lino De Ros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b03aa8",
   "metadata": {},
   "source": [
    "## 1. \n",
    "\n",
    "- What is the expected value of a single die roll?\n",
    "\n",
    "$E[die]=\\frac{1+2+3+4+5+6}{6}=\\frac{21}{6}=3.5$\n",
    "\n",
    "- What is the expected value of rolling two dice and adding the results together?\n",
    "\n",
    "$E[X]=2(E[die])=7$\n",
    "\n",
    "- What is the expected winnings of any gamble in European roulette?\n",
    "\n",
    "Since there are 37 numbers in a roulette wheel, the probability of winning is $\\frac{18}{37}$ and the probability of losing is $\\frac{19}{37}$, because of the single 0. So, for any bet, the expected winnings is $\\frac{18}{37} - \\frac{19}{37} = -\\frac{1}{37}$ or about $-2.7\\%$.\n",
    "\n",
    "- Imagine you roll a die, and you record the value you get. But, if you roll a six, you roll again, and add that value. What is the expected value?\n",
    "\n",
    "Again, $E[die]=3.5$. The probability of rolling a 6 is $\\frac{1}{6}$. Then, the expected value from re-rolling on the 6 would be 3.5. So, to combine these probabilities, we must find $3.5+\\left(3.5\\times \\frac{1}{6}\\right) = \\frac{49}{12}$, or about 4.08.\n",
    "\n",
    "- Imagine that the process described in the last question continues until you fail to roll a six. What is the expected value of the process? (This can be tricky, you can simulate it to get an answer if you prefer. Hint: The answer is 4.2.)\n",
    "\n",
    "To answer this question, we starting by finding the probability and expected value of not rolling 6. The probability is $\\frac{5}{6}$ and the expected value is $\\frac{1+2+3+4+5}{5}=3$. Then, we find the probability and expected value of rolling 6. The probability is $\\frac{1}{6}$, but the expected value is a bit more complicated. We end up with 6 plues a new copy of the whole process, which comes out to $6+E[X]$. Now, we can write out the whole expectation equation:\n",
    "\n",
    "$E[X]=\\frac{5}{6}(3)+\\frac{1}{6}(6+E[X])$\n",
    "\n",
    "This equation simplifies to $E[X]=\\frac{21}{5}$ or $4.2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2364a41c",
   "metadata": {},
   "source": [
    "## 2. \n",
    "- Compute the expected value for a uniform random variable.\n",
    "\n",
    "If $X$ is uniformly distributed over a range of values within a range where $a\\leq x\\leq b$, then $E[X]=\\frac{a+b}{2}$.\n",
    "\n",
    "- Show that $\\mathbb{E}[a+bX] = a + b\\mathbb{E}[X]$\n",
    "\n",
    "If $X$ has density $f(x)$, then:\n",
    "$$\n",
    "\\mathbb{E}[a+bX]=\\int_{-\\infty}^{\\infty}(a+bx)f(x)dx\n",
    "$$\n",
    "Distribute inside integral:\n",
    "$$\n",
    "=\\int af(x)dx+\\int bxf(x)dx\n",
    "$$\n",
    "Pull out constants:\n",
    "$$\n",
    "=a\\int f(x)dx+b\\int xf(x)dx\n",
    "$$\n",
    "where:\n",
    "* $\\int f(x)dx=1$\n",
    "* $\\int xf(x)dx=\\mathbb{E}[X]$\n",
    "\n",
    "So:\n",
    "$$\n",
    "\\mathbb{E}[a+bX] = a + b\\mathbb{E}[X]\n",
    "$$\n",
    "- Show, by example, that $v(\\mathbb{E}[X]) \\neq \\mathbb{E}[v(X)]$, if $v(x) \\neq a+bx$. For example, try $v(y) = y^2$ or $v(y)=\\sqrt{y}$ with a Bernoulli or uniform or normally distributed random variable. This can be an important thing to remember: The expectation of a transformed random variable is not the transformation of the expected value.\n",
    "\n",
    "$v(y)=\\sqrt{y}, X \\sim \\text{Uniform}(0,1)$\n",
    "\n",
    "1. Compute $\\mathbb{E}[X]$:\n",
    "$$\n",
    "\\mathbb{E}[X]=\\int_0^1 xdx=\\left[\\frac{x^2}{2}\\right]_0^1=\\frac{1}{2}\n",
    "$$\n",
    "2. Compute $v(\\mathbb{E}[X])$:\n",
    "$$\n",
    "v(\\mathbb{E}[X])=\\sqrt{\\frac{1}{2}}=\\frac{1}{\\sqrt{2}}\n",
    "$$\n",
    "3. Compute $\\mathbb{E}[v(X)]=\\mathbb{E}[\\sqrt{X}]$:\n",
    "$$\n",
    "\\mathbb{E}[\\sqrt{X}]=\\int_0^1 \\sqrt{x}dx=\\left[\\frac{2}{3}x^{3/2}\\right]_0^1=\\frac{2}{3}\n",
    "$$\n",
    "4. Compare the results:\n",
    "$$\n",
    "v(\\mathbb{E}[X])=\\frac{1}{\\sqrt{2}}\\approx 0.707\n",
    "$$\n",
    "$$\n",
    "\\mathbb{E}[v(X)]=\\frac{2}{3}\\approx 0.667\n",
    "$$\n",
    "5. Conclude:\n",
    "$$\n",
    "v(\\mathbb{E}[X]) \\neq \\mathbb{E}[v(X)]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56564ad3",
   "metadata": {},
   "source": [
    "## 3. \n",
    "- Compute the variance for a uniform random variable.\n",
    "1. Compute $\\mathbb{E}[X]$ for $X \\sim \\text{Unif}(a,b)$:\n",
    "$$\n",
    "\\mathbb{E}[X] = \\int_a^b x \\cdot \\frac{1}{b-a}\\,dx \n",
    "= \\frac{1}{b-a}\\left[\\frac{x^2}{2}\\right]_a^b\n",
    "= \\frac{1}{2(b-a)}(b^2 - a^2)\n",
    "$$\n",
    "$$\n",
    "\\mathbb{E}[X] = \\frac{a+b}{2}\n",
    "$$\n",
    "\n",
    "2. Compute $\\mathbb{E}[X^2]$:\n",
    "$$\n",
    "\\mathbb{E}[X^2] = \\int_a^b x^2 \\cdot \\frac{1}{b-a}\\,dx\n",
    "= \\frac{1}{b-a}\\left[\\frac{x^3}{3}\\right]_a^b\n",
    "= \\frac{1}{3(b-a)}(b^3 - a^3)\n",
    "$$\n",
    "$$\n",
    "\\mathbb{E}[X^2] = \\frac{a^2 + ab + b^2}{3}\n",
    "$$\n",
    "\n",
    "3. Use the variance identity:\n",
    "$$\n",
    "\\mathbb{V}[X] = \\mathbb{E}[X^2] - \\mathbb{E}[X]^2\n",
    "$$\n",
    "\n",
    "4. Substitute the computed values:\n",
    "$$\n",
    "\\mathbb{V}[X] \n",
    "= \\frac{a^2 + ab + b^2}{3} - \\left(\\frac{a+b}{2}\\right)^2\n",
    "$$\n",
    "\n",
    "5. Simplify the expression:\n",
    "$$\n",
    "\\mathbb{V}[X] \n",
    "= \\frac{a^2 + ab + b^2}{3} - \\frac{a^2 + 2ab + b^2}{4}\n",
    "$$\n",
    "$$\n",
    "\\mathbb{V}[X] \n",
    "= \\frac{4(a^2 + ab + b^2) - 3(a^2 + 2ab + b^2)}{12}\n",
    "$$\n",
    "$$\n",
    "\\mathbb{V}[X] \n",
    "= \\frac{b^2 - 2ab + a^2}{12}\n",
    "$$\n",
    "\n",
    "6. Recognize the factor:\n",
    "$$\n",
    "b^2 - 2ab + a^2 = (b - a)^2\n",
    "$$\n",
    "\n",
    "7. Conclude:\n",
    "$$\n",
    "\\mathbb{V}[X] = \\frac{(b - a)^2}{12}\n",
    "$$\n",
    "\n",
    "\n",
    "- Show that \n",
    "$$\n",
    "\\mathbb{V}[X] = \\mathbb{E}[X^2] - \\mathbb{E}[X]^2\n",
    "$$\n",
    "$$\n",
    "\\mathbb{V}[a+bX] = b^2 \\mathbb{V}[X]\n",
    "$$\n",
    "\n",
    "1. Start with the definition of variance:\n",
    "$$\n",
    "\\mathbb{V}[X] = \\mathbb{E}\\big[(X - \\mathbb{E}[X])^2\\big]\n",
    "$$\n",
    "\n",
    "2. Expand the square:\n",
    "$$\n",
    "(X - \\mathbb{E}[X])^2 = X^2 - 2X\\mathbb{E}[X] + \\mathbb{E}[X]^2\n",
    "$$\n",
    "\n",
    "3. Apply linearity of expectation:\n",
    "$$\n",
    "\\mathbb{V}[X] = \\mathbb{E}[X^2] - 2\\mathbb{E}[X]\\mathbb{E}[X] + \\mathbb{E}[X]^2\n",
    "$$\n",
    "\n",
    "4. Simplify:\n",
    "$$\n",
    "\\mathbb{V}[X] = \\mathbb{E}[X^2] - \\mathbb{E}[X]^2\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "5. Compute $\\mathbb{V}[a + bX]$:\n",
    "$$\n",
    "\\mathbb{V}[a + bX] = \\mathbb{E}\\big[(a + bX - \\mathbb{E}[a + bX])^2\\big]\n",
    "$$\n",
    "\n",
    "6. Use linearity of expectation:\n",
    "$$\n",
    "\\mathbb{E}[a + bX] = a + b\\mathbb{E}[X]\n",
    "$$\n",
    "\n",
    "7. Substitute:\n",
    "$$\n",
    "a + bX - (a + b\\mathbb{E}[X]) = b(X - \\mathbb{E}[X])\n",
    "$$\n",
    "\n",
    "8. Rewrite the variance:\n",
    "$$\n",
    "\\mathbb{V}[a + bX] = \\mathbb{E}\\big[b^2 (X - \\mathbb{E}[X])^2\\big]\n",
    "$$\n",
    "\n",
    "9. Pull out the constant:\n",
    "$$\n",
    "\\mathbb{V}[a + bX] = b^2 \\mathbb{E}\\big[(X - \\mathbb{E}[X])^2\\big]\n",
    "$$\n",
    "\n",
    "10. Conclude:\n",
    "$$\n",
    "\\mathbb{V}[a + bX] = b^2 \\mathbb{V}[X]\n",
    "$$\n",
    "- Show that if $X$ is a normally distributed random variable, then $a + bX$ is distributed normally with mean $a+ b \\mathbb{E}[X]$ and variance $b^2 \\sigma_X^2$ \n",
    "\n",
    "1. Let $X$ be a normally distributed random variable:\n",
    "$$\n",
    "X \\sim \\mathcal{N}(\\mu_X, \\sigma_X^2)\n",
    "$$\n",
    "so its density is\n",
    "$$\n",
    "f_X(x) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma_X}\n",
    "\\exp\\left( -\\frac{(x - \\mu_X)^2}{2\\sigma_X^2} \\right).\n",
    "$$\n",
    "\n",
    "2. Define a new random variable $Y$ as an affine transformation of $X$:\n",
    "$$\n",
    "Y = a + bX, \\quad b \\neq 0.\n",
    "$$\n",
    "\n",
    "3. Compute the mean of $Y$ using linearity of expectation:\n",
    "$$\n",
    "\\mathbb{E}[Y] = \\mathbb{E}[a + bX] = a + b\\,\\mathbb{E}[X] = a + b\\mu_X.\n",
    "$$\n",
    "\n",
    "4. Compute the variance of $Y$ using $\\mathbb{V}[a + bX] = b^2 \\mathbb{V}[X]$:\n",
    "$$\n",
    "\\mathbb{V}[Y] = \\mathbb{V}[a + bX] = b^2 \\mathbb{V}[X] = b^2 \\sigma_X^2.\n",
    "$$\n",
    "\n",
    "5. Find the density of $Y$ using a change of variables. Since\n",
    "$$\n",
    "Y = a + bX \\quad \\Longleftrightarrow \\quad X = \\frac{Y - a}{b},\n",
    "$$\n",
    "we have\n",
    "$$\n",
    "f_Y(y) = \\frac{1}{|b|} f_X\\!\\left(\\frac{y - a}{b}\\right).\n",
    "$$\n",
    "\n",
    "6. Substitute the expression for $f_X$:\n",
    "$$\n",
    "f_Y(y)\n",
    "= \\frac{1}{|b|} \\cdot \n",
    "\\frac{1}{\\sqrt{2\\pi}\\,\\sigma_X}^{\\left(\n",
    "-\\frac{\\left(\\frac{y - a}{b} - \\mu_X\\right)^2}{2\\sigma_X^2}\n",
    "\\right)}\n",
    "$$\n",
    "\n",
    "7. Simplify the exponent:\n",
    "$$\n",
    "\\frac{y - a}{b} - \\mu_X\n",
    "= \\frac{y - a - b\\mu_X}{b},\n",
    "$$\n",
    "so\n",
    "$$\n",
    "\\left(\\frac{y - a}{b} - \\mu_X\\right)^2\n",
    "= \\frac{(y - a - b\\mu_X)^2}{b^2}.\n",
    "$$\n",
    "Then the exponent becomes\n",
    "$$\n",
    "-\\frac{(y - a - b\\mu_X)^2}{2 b^2 \\sigma_X^2}.\n",
    "$$\n",
    "\n",
    "8. Write the final form of $f_Y(y)$:\n",
    "$$\n",
    "f_Y(y)\n",
    "= \\frac{1}{\\sqrt{2\\pi}\\,|b|\\sigma_X}^{\\left(\n",
    "-\\frac{(y - (a + b\\mu_X))^2}{2 b^2 \\sigma_X^2}\n",
    "\\right)}\n",
    "$$\n",
    "\n",
    "9. Recognize this as the density of a normal distribution with mean $a + b\\mu_X$ and variance $b^2\\sigma_X^2$:\n",
    "$$\n",
    "Y \\sim \\mathcal{N}\\big(a + b\\mu_X,\\; b^2\\sigma_X^2\\big).\n",
    "$$\n",
    "\n",
    "10. Conclude:\n",
    "$$\n",
    "\\text{If } X \\text{ is normal, then } a + bX \\text{ is normal with}\n",
    "$$\n",
    "$$\n",
    "\\mathbb{E}[a + bX] = a + b\\,\\mathbb{E}[X], \\qquad\n",
    "\\mathbb{V}[a + bX] = b^2 \\sigma_X^2.\n",
    "$$\n",
    "\n",
    "\n",
    "These properties get used all the time!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6744a1",
   "metadata": {},
   "source": [
    "## 4.\n",
    "\n",
    "- The **covariance** of $X$ and $Y$ is\n",
    "$$\n",
    "\\text{cov}(X,Y) = \\int_{y} \\int_{x} (x-\\mathbb{E}[X])(y-\\mathbb{E}[Y])f_{XY}(x,y) dxdy = \\mathbb{E}_{XY}[ (x-\\mu_X)(y-\\mu_Y)]\n",
    "$$\n",
    "- Show that if $f_{XY}(x,y)=f_X(x)f_Y(y)$, then $\\text{cov}(X,Y)=0$\n",
    "\n",
    "1. Assume $X$ and $Y$ are independent so that their joint density factorizes:\n",
    "$$\n",
    "f_{XY}(x,y) = f_X(x)\\,f_Y(y).\n",
    "$$\n",
    "\n",
    "2. Substitute the factorized joint density into the covariance integral:\n",
    "$$\n",
    "\\operatorname{cov}(X,Y) \n",
    "= \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} (x - \\mu_X)(y - \\mu_Y) f_X(x) f_Y(y)\\,dx\\,dy.\n",
    "$$\n",
    "\n",
    "3. Separate the integrals (Fubini/Tonelli and product structure):\n",
    "$$\n",
    "\\operatorname{cov}(X,Y) \n",
    "= \\left( \\int_{-\\infty}^{\\infty} (x - \\mu_X) f_X(x)\\,dx \\right)\n",
    "  \\left( \\int_{-\\infty}^{\\infty} (y - \\mu_Y) f_Y(y)\\,dy \\right).\n",
    "$$\n",
    "\n",
    "4. Recognize each factor as a centered expectation:\n",
    "$$\n",
    "\\int_{-\\infty}^{\\infty} (x - \\mu_X) f_X(x)\\,dx\n",
    "= \\mathbb{E}[X - \\mu_X] = \\mathbb{E}[X] - \\mu_X = 0,\n",
    "$$\n",
    "$$\n",
    "\\int_{-\\infty}^{\\infty} (y - \\mu_Y) f_Y(y)\\,dy\n",
    "= \\mathbb{E}[Y - \\mu_Y] = \\mathbb{E}[Y] - \\mu_Y = 0.\n",
    "$$\n",
    "\n",
    "5. Multiply the factors:\n",
    "$$\n",
    "\\operatorname{cov}(X,Y) = 0 \\cdot 0 = 0.\n",
    "$$\n",
    "\n",
    "6. Conclude:\n",
    "$$\n",
    "\\text{If } f_{XY}(x,y) = f_X(x) f_Y(y), \\text{ then } \\operatorname{cov}(X,Y) = 0.\n",
    "$$\n",
    "\n",
    "- Provide an example (computation/simulation is fine) where $\\text{cov}(X,Y)\\approx 0$ but $f_{XY}(x,y)\\neq 0$\n",
    "\n",
    "1. Define a discrete random variable $X$ taking values in $\\{-1,0,1\\}$:\n",
    "$$\n",
    "\\mathbb{P}(X = -1) = \\mathbb{P}(X = 0) = \\mathbb{P}(X = 1) = \\frac{1}{3}.\n",
    "$$\n",
    "\n",
    "2. Define $Y$ as a function of $X$:\n",
    "$$\n",
    "Y = X^2.\n",
    "$$\n",
    "Then $Y$ takes values in $\\{0,1\\}$ with\n",
    "$$\n",
    "\\mathbb{P}(Y = 0) = \\mathbb{P}(X = 0) = \\frac{1}{3}, \\qquad\n",
    "\\mathbb{P}(Y = 1) = \\mathbb{P}(X = -1 \\text{ or } X = 1) = \\frac{2}{3}.\n",
    "$$\n",
    "\n",
    "3. Compute $\\mathbb{E}[X]$:\n",
    "$$\n",
    "\\mathbb{E}[X] = (-1)\\cdot\\frac{1}{3} + 0\\cdot\\frac{1}{3} + 1\\cdot\\frac{1}{3}\n",
    "= -\\frac{1}{3} + 0 + \\frac{1}{3} = 0.\n",
    "$$\n",
    "\n",
    "4. Compute $\\mathbb{E}[Y]$:\n",
    "$$\n",
    "\\mathbb{E}[Y] = 0\\cdot\\mathbb{P}(Y=0) + 1\\cdot\\mathbb{P}(Y=1)\n",
    "= 0\\cdot\\frac{1}{3} + 1\\cdot\\frac{2}{3} = \\frac{2}{3}.\n",
    "$$\n",
    "\n",
    "5. Compute $\\mathbb{E}[XY]$.\n",
    "Note that $Y = X^2$, so $XY = X \\cdot X^2 = X^3$. Thus\n",
    "$$\n",
    "\\mathbb{E}[XY] = \\mathbb{E}[X^3]\n",
    "= (-1)^3\\cdot\\frac{1}{3} + 0^3\\cdot\\frac{1}{3} + 1^3\\cdot\\frac{1}{3}\n",
    "= -\\frac{1}{3} + 0 + \\frac{1}{3} = 0.\n",
    "$$\n",
    "\n",
    "6. Compute the covariance:\n",
    "$$\n",
    "\\operatorname{cov}(X,Y) \n",
    "= \\mathbb{E}[XY] - \\mathbb{E}[X]\\,\\mathbb{E}[Y]\n",
    "= 0 - (0)\\left(\\frac{2}{3}\\right) = 0.\n",
    "$$\n",
    "\n",
    "7. Compute the joint distribution $p_{XY}(x,y)$:\n",
    "\n",
    "\\begin{array}{c|cc}\n",
    " & Y=0 & Y=1 \\\\ \\hline\n",
    "X=-1 & 0 & \\frac{1}{3} \\\\\n",
    "X=0  & \\frac{1}{3} & 0 \\\\\n",
    "X=1  & 0 & \\frac{1}{3}\n",
    "\\end{array}\n",
    "\n",
    "so, for example,\n",
    "$$\n",
    "p_{XY}(1,1) = \\mathbb{P}(X=1, Y=1) = \\frac{1}{3}.\n",
    "$$\n",
    "\n",
    "8. Compute the product of marginals at $(x,y) = (1,1)$:\n",
    "$$\n",
    "p_X(1) = \\frac{1}{3}, \\qquad\n",
    "p_Y(1) = \\frac{2}{3},\n",
    "$$\n",
    "so\n",
    "$$\n",
    "p_X(1)\\,p_Y(1) = \\frac{1}{3}\\cdot\\frac{2}{3} = \\frac{2}{9}.\n",
    "$$\n",
    "\n",
    "9. Compare the joint and product of marginals:\n",
    "$$\n",
    "p_{XY}(1,1) = \\frac{1}{3} \\neq \\frac{2}{9} = p_X(1)\\,p_Y(1).\n",
    "$$\n",
    "\n",
    "10. Conclude:\n",
    "\n",
    "- The covariance is zero:\n",
    "$$\n",
    "\\operatorname{cov}(X,Y) = 0,\n",
    "$$\n",
    "- but $X$ and $Y$ are not independent because\n",
    "$$\n",
    "p_{XY}(x,y) \\neq p_X(x)\\,p_Y(y).\n",
    "$$\n",
    "\n",
    "Thus, this example shows that $\\operatorname{cov}(X,Y) =0$ does not imply independence.\n",
    "\n",
    "- The covariance doesn't characterize joint random variables except in a few special cases: The covariance only captures the **linear** association between the two variables, not nonlinear associations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3cc8aa",
   "metadata": {},
   "source": [
    "## 7.\n",
    "- Suppose $X$ and $Y$ are distributed bivariate normal. Show that if $\\rho=0$, then $X$ and $Y$ are independent.\n",
    "\n",
    "1. In the case $\\rho = 0$. Then the joint density simplifies to\n",
    "$$\n",
    "f_{X,Y}(x,y)\n",
    "= \\frac{1}{2\\pi\\,\\sigma_X \\sigma_Y}\n",
    "^{\\left(\n",
    "-\\frac{1}{2}\n",
    "\\left[\n",
    "\\frac{(x-\\mu_X)^2}{\\sigma_X^2}\n",
    "+ \\frac{(y-\\mu_Y)^2}{\\sigma_Y^2}\n",
    "\\right]\n",
    "\\right)}\n",
    "$$\n",
    "\n",
    "2. Separate the exponential into a product:\n",
    "$$\n",
    "\\exp\\left(\n",
    "-\\frac{1}{2}\n",
    "\\left[\n",
    "\\frac{(x-\\mu_X)^2}{\\sigma_X^2}\n",
    "+ \\frac{(y-\\mu_Y)^2}{\\sigma_Y^2}\n",
    "\\right]\n",
    "\\right)\n",
    "=\n",
    "\\exp\\left(-\\frac{(x-\\mu_X)^2}{2\\sigma_X^2}\\right)\n",
    "\\exp\\left(-\\frac{(y-\\mu_Y)^2}{2\\sigma_Y^2}\\right).\n",
    "$$\n",
    "\n",
    "3. Rewrite the joint density as a product:\n",
    "$$\n",
    "f_{X,Y}(x,y)\n",
    "= \\left[\n",
    "\\frac{1}{\\sqrt{2\\pi}\\,\\sigma_X}\n",
    "^{\\left(-\\frac{(x-\\mu_X)^2}{2\\sigma_X^2}\\right)}\n",
    "\\right]\n",
    "\\left[\n",
    "\\frac{1}{\\sqrt{2\\pi}\\,\\sigma_Y}^{\\left(-\\frac{(y-\\mu_Y)^2}{2\\sigma_Y^2}\\right)}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "4. Recognize each factor as a univariate normal density:\n",
    "$$\n",
    "f_X(x) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma_X}^{\\left(-\\frac{(x-\\mu_X)^2}{2\\sigma_X^2}\\right)},\n",
    "$$\n",
    "$$\n",
    "f_Y(y) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma_Y}^{\\left(-\\frac{(y-\\mu_Y)^2}{2\\sigma_Y^2}\\right)}\n",
    "$$\n",
    "\n",
    "5. Therefore,\n",
    "$$\n",
    "f_{X,Y}(x,y) = f_X(x)\\,f_Y(y).\n",
    "$$\n",
    "\n",
    "6. By definition, if the joint density factorizes as a product of marginals, $X$ and $Y$ are independent.\n",
    "\n",
    "7. Conclude:\n",
    "$$\n",
    "\\text{For a bivariate normal $(X,Y)$, if } \\rho = 0,\\ \\text{ then } X \\text{ and } Y \\text{ are independent.}\n",
    "$$\n",
    "\n",
    "\n",
    "- For the multivariate normal, show that if $\\Sigma$ is a diagonal matrix, then $X_1, X_2, ..., X_n$ are independent.\n",
    "\n",
    "1. Let $X = (X_1, X_2, \\dots, X_n)$ be an $n$-dimensional multivariate normal:\n",
    "$$\n",
    "X \\sim \\mathcal{N}(\\mu, \\Sigma),\n",
    "$$\n",
    "where $\\mu = (\\mu_1,\\dots,\\mu_n)$ and $\\Sigma$ is the covariance matrix.\n",
    "\n",
    "2. Suppose $\\Sigma$ is diagonal:\n",
    "$$\n",
    "\\Sigma = \n",
    "\\begin{pmatrix}\n",
    "\\sigma_1^2 & 0 & \\cdots & 0 \\\\\n",
    "0 & \\sigma_2^2 & \\cdots & 0 \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "0 & 0 & \\cdots & \\sigma_n^2\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "3. The multivariate normal density is\n",
    "$$\n",
    "f_X(x) = \n",
    "\\frac{1}{(2\\pi)^{n/2} |\\Sigma|^{1/2}}\n",
    "^{\\left(\n",
    "-\\frac{1}{2}(x-\\mu)^\\top \\Sigma^{-1}(x-\\mu)\n",
    "\\right)}\n",
    "$$\n",
    "\n",
    "4. If $\\Sigma$ is diagonal, then $\\Sigma^{-1}$ is also diagonal:\n",
    "$$\n",
    "\\Sigma^{-1}\n",
    "= \\operatorname{diag}\\left(\\frac{1}{\\sigma_1^2},\\dots,\\frac{1}{\\sigma_n^2}\\right),\n",
    "$$\n",
    "so the quadratic form becomes a sum of independent terms:\n",
    "$$\n",
    "(x-\\mu)^\\top \\Sigma^{-1}(x-\\mu)\n",
    "= \\sum_{i=1}^n \\frac{(x_i - \\mu_i)^2}{\\sigma_i^2}.\n",
    "$$\n",
    "\n",
    "5. Substitute into the density:\n",
    "$$\n",
    "f_X(x) =\n",
    "\\frac{1}{(2\\pi)^{n/2} \\prod_{i=1}^n \\sigma_i}^{\\left(\n",
    "-\\frac{1}{2}\\sum_{i=1}^n \\frac{(x_i - \\mu_i)^2}{\\sigma_i^2}\n",
    "\\right)}\n",
    "$$\n",
    "\n",
    "6. Separate the exponential into a product:\n",
    "$$\n",
    "\\exp\\left(\n",
    "-\\frac{1}{2}\\sum_{i=1}^n \\frac{(x_i - \\mu_i)^2}{\\sigma_i^2}\n",
    "\\right)\n",
    "=\n",
    "\\prod_{i=1}^n\n",
    "\\exp\\left(\n",
    "-\\frac{(x_i - \\mu_i)^2}{2\\sigma_i^2}\n",
    "\\right).\n",
    "$$\n",
    "\n",
    "7. Rewrite the density as a product of factorized terms:\n",
    "$$\n",
    "f_X(x)\n",
    "=\n",
    "\\prod_{i=1}^n\n",
    "\\left[\n",
    "\\frac{1}{\\sqrt{2\\pi}\\,\\sigma_i}^{\\left(\n",
    "-\\frac{(x_i - \\mu_i)^2}{2\\sigma_i^2}\n",
    "\\right)}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "8. Recognize each factor as the marginal density of $X_i$:\n",
    "$$\n",
    "f_{X_i}(x_i)\n",
    "=\n",
    "\\frac{1}{\\sqrt{2\\pi}\\,\\sigma_i}^{\\left(\n",
    "-\\frac{(x_i - \\mu_i)^2}{2\\sigma_i^2}\n",
    "\\right)}\n",
    "$$\n",
    "\n",
    "9. Thus the joint density factorizes:\n",
    "$$\n",
    "f_X(x) = \\prod_{i=1}^n f_{X_i}(x_i).\n",
    "$$\n",
    "\n",
    "10. By definition, factorization of the joint density into marginal densities implies independence.\n",
    "\n",
    "11. Conclude:\n",
    "$$\n",
    "\\text{If a multivariate normal has a diagonal covariance matrix,}\n",
    "\\quad X_1, X_2, \\dots, X_n \\text{ are independent.}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "- For the multivariate normal, show that if $\\Sigma$ is a diagonal matrix and all the $\\sigma_i^2$ and all the $\\mu_i$ are equal, then $X_1, X_2, ..., X_n$ are independently distributed random variables with distribution $N(\\mu, \\sigma^2)$\n",
    "\n",
    "1. Let $X = (X_1, X_2, \\dots, X_n)$ be multivariate normal:\n",
    "$$\n",
    "X \\sim \\mathcal{N}(\\mu, \\Sigma),\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\mu = (\\mu_1, \\mu_2, \\dots, \\mu_n), \n",
    "\\qquad\n",
    "\\Sigma = \\operatorname{diag}(\\sigma_1^2, \\sigma_2^2, \\dots, \\sigma_n^2).\n",
    "$$\n",
    "\n",
    "2. Assume all means are equal:\n",
    "$$\n",
    "\\mu_1 = \\mu_2 = \\cdots = \\mu_n = \\mu,\n",
    "$$\n",
    "and all variances are equal:\n",
    "$$\n",
    "\\sigma_1^2 = \\sigma_2^2 = \\cdots = \\sigma_n^2 = \\sigma^2.\n",
    "$$\n",
    "\n",
    "3. Substitute these into the covariance matrix:\n",
    "$$\n",
    "\\Sigma = \n",
    "\\begin{pmatrix}\n",
    "\\sigma^2 & 0 & \\cdots & 0 \\\\\n",
    "0 & \\sigma^2 & \\cdots & 0 \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "0 & 0 & \\cdots & \\sigma^2\n",
    "\\end{pmatrix}\n",
    "= \\sigma^2 I_n,\n",
    "$$\n",
    "and into the mean vector:\n",
    "$$\n",
    "\\mu = (\\mu, \\mu, \\dots, \\mu).\n",
    "$$\n",
    "\n",
    "4. The multivariate normal density becomes\n",
    "$$\n",
    "f_X(x) = \n",
    "\\frac{1}{(2\\pi)^{n/2} |\\Sigma|^{1/2}}^{\\left(\n",
    "-\\frac{1}{2}(x-\\mu)^\\top \\Sigma^{-1}(x-\\mu)\n",
    "\\right)}\n",
    "$$\n",
    "\n",
    "5. Since $\\Sigma = \\sigma^2 I_n$, we have\n",
    "$$\n",
    "|\\Sigma| = (\\sigma^2)^n = \\sigma^{2n},\n",
    "\\qquad\n",
    "\\Sigma^{-1} = \\frac{1}{\\sigma^2} I_n.\n",
    "$$\n",
    "\n",
    "6. Substitute these into the quadratic form:\n",
    "$$\n",
    "(x - \\mu)^\\top \\Sigma^{-1} (x - \\mu)\n",
    "= \\frac{1}{\\sigma^2} \\sum_{i=1}^n (x_i - \\mu)^2.\n",
    "$$\n",
    "\n",
    "7. Substitute into the density:\n",
    "$$\n",
    "f_X(x)\n",
    "= \\frac{1}{(2\\pi)^{n/2}\\sigma^n}\n",
    "^{\\left(\n",
    "-\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (x_i - \\mu)^2\n",
    "\\right)}\n",
    "$$\n",
    "\n",
    "8. Separate into a product over coordinates:\n",
    "$$\n",
    "f_X(x)\n",
    "= \\prod_{i=1}^n \n",
    "\\left[\n",
    "\\frac{1}{\\sqrt{2\\pi}\\sigma}^{\\left(\n",
    "-\\frac{(x_i - \\mu)^2}{2\\sigma^2}\n",
    "\\right)}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "9. Recognize each factor as the density of a univariate normal:\n",
    "$$\n",
    "f_{X_i}(x_i)\n",
    "= \\frac{1}{\\sqrt{2\\pi}\\sigma}^{\\left(\n",
    "-\\frac{(x_i - \\mu)^2}{2\\sigma^2}\n",
    "\\right)},\n",
    "$$\n",
    "which is exactly\n",
    "$$\n",
    "X_i \\sim \\mathcal{N}(\\mu, \\sigma^2).\n",
    "$$\n",
    "\n",
    "10. Since the joint density factorizes:\n",
    "$$\n",
    "f_X(x) = \\prod_{i=1}^n f_{X_i}(x_i),\n",
    "$$\n",
    "the random variables $X_1, X_2, \\dots, X_n$ are independent.\n",
    "\n",
    "11. Conclude:\n",
    "\n",
    "$\\text{If } \\Sigma = \\sigma^2 I_n \\text{ and } \\mu_i = \\mu, \\sigma_i^2 = \\sigma^2,\n",
    "\\text{ then } X_1,\\dots,X_n$\n",
    "\n",
    "$\\text{ are independently distributed random variables with distribution } \\mathcal{N}(\\mu, \\sigma^2)$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds6001",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
